{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import partial\n",
    "\n",
    "REGEX_MULTI_SPACE = re.compile(\"\\s+\")\n",
    "\n",
    "\n",
    "def preprocess_text(_re, _regex, s):\n",
    "    return {\n",
    "        \"text\": _re.sub(_regex, \" \", s[\"title\"])\n",
    "        # + \"\\n\\n\"\n",
    "        # + _re.sub(_regex, \" \", s[\"abstract\"])\n",
    "    }\n",
    "    \n",
    "partial_preprocess_text = partial(preprocess_text, re, REGEX_MULTI_SPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'abstract', 'text'],\n",
       "        num_rows: 105832\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'abstract', 'text'],\n",
       "        num_rows: 11760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"aalksii/ml-arxiv-papers\")\n",
    "dataset = dataset.map(\n",
    "    partial_preprocess_text,\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7025e7501a5c4708b505b5d111bfc962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianch\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ianch\\.cache\\huggingface\\hub\\models--distilroberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f858840832494245b145420d2acb5c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635a49b6205f40d38cdf4a535658b5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0674071c9d1a4dca87e00d623dc26e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
    "\n",
    "# def add_tokens(tokenizer, new_tokens):\n",
    "    # new_tokens = set(new_tokens) - set(tokenizer.vocab.keys())\n",
    "    # tokenizer.add_tokens(list(new_tokens))\n",
    "    # return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6642ff7f072a48788e7373c1479ec552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/105832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d25b02ae8dc4e2781841011ba458722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/11760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(tokenizer, examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "\n",
    "partial_tokenize_function = partial(tokenize_function, tokenizer)\n",
    "\n",
    "tokens = dataset.map(\n",
    "    partial_tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b8a78e3dda433087ffa81f97248222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4d37ca8f1a4d2a8f1a8aa7fea6f8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2395, 'learning_rate': 1.975004409504372e-05, 'epoch': 0.04}\n",
      "{'loss': 2.9825, 'learning_rate': 1.949807241666037e-05, 'epoch': 0.08}\n",
      "{'loss': 2.7744, 'learning_rate': 1.924610073827702e-05, 'epoch': 0.11}\n",
      "{'loss': 2.7988, 'learning_rate': 1.899412905989367e-05, 'epoch': 0.15}\n",
      "{'loss': 2.762, 'learning_rate': 1.8742157381510318e-05, 'epoch': 0.19}\n",
      "{'loss': 2.6762, 'learning_rate': 1.849018570312697e-05, 'epoch': 0.23}\n",
      "{'loss': 2.7256, 'learning_rate': 1.823821402474362e-05, 'epoch': 0.26}\n",
      "{'loss': 2.7004, 'learning_rate': 1.7986746289717036e-05, 'epoch': 0.3}\n",
      "{'loss': 2.6525, 'learning_rate': 1.7734774611333687e-05, 'epoch': 0.34}\n",
      "{'loss': 2.5652, 'learning_rate': 1.748280293295034e-05, 'epoch': 0.38}\n",
      "{'loss': 2.5228, 'learning_rate': 1.723083125456699e-05, 'epoch': 0.42}\n",
      "{'loss': 2.597, 'learning_rate': 1.6979363519540405e-05, 'epoch': 0.45}\n",
      "{'loss': 2.475, 'learning_rate': 1.6727391841157053e-05, 'epoch': 0.49}\n",
      "{'loss': 2.5657, 'learning_rate': 1.6475420162773704e-05, 'epoch': 0.53}\n",
      "{'loss': 2.455, 'learning_rate': 1.6223448484390356e-05, 'epoch': 0.57}\n",
      "{'loss': 2.5102, 'learning_rate': 1.5971476806007007e-05, 'epoch': 0.6}\n",
      "{'loss': 2.4338, 'learning_rate': 1.5720009070980422e-05, 'epoch': 0.64}\n",
      "{'loss': 2.4719, 'learning_rate': 1.5468037392597074e-05, 'epoch': 0.68}\n",
      "{'loss': 2.4767, 'learning_rate': 1.5216065714213723e-05, 'epoch': 0.72}\n",
      "{'loss': 2.4045, 'learning_rate': 1.4964094035830374e-05, 'epoch': 0.76}\n",
      "{'loss': 2.4698, 'learning_rate': 1.4712122357447026e-05, 'epoch': 0.79}\n",
      "{'loss': 2.3757, 'learning_rate': 1.4460150679063674e-05, 'epoch': 0.83}\n",
      "{'loss': 2.4295, 'learning_rate': 1.420868294403709e-05, 'epoch': 0.87}\n",
      "{'loss': 2.3621, 'learning_rate': 1.3956711265653742e-05, 'epoch': 0.91}\n",
      "{'loss': 2.3942, 'learning_rate': 1.3704739587270393e-05, 'epoch': 0.94}\n",
      "{'loss': 2.3071, 'learning_rate': 1.3452767908887041e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e274afdb13044359f04ceb8f7fb2d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2009363174438477, 'eval_runtime': 19.696, 'eval_samples_per_second': 597.077, 'eval_steps_per_second': 74.635, 'epoch': 1.0}\n",
      "{'loss': 2.2936, 'learning_rate': 1.3200796230503692e-05, 'epoch': 1.02}\n",
      "{'loss': 2.3287, 'learning_rate': 1.294932849547711e-05, 'epoch': 1.06}\n",
      "{'loss': 2.2704, 'learning_rate': 1.269735681709376e-05, 'epoch': 1.1}\n",
      "{'loss': 2.2588, 'learning_rate': 1.244538513871041e-05, 'epoch': 1.13}\n",
      "{'loss': 2.331, 'learning_rate': 1.219341346032706e-05, 'epoch': 1.17}\n",
      "{'loss': 2.2291, 'learning_rate': 1.194144178194371e-05, 'epoch': 1.21}\n",
      "{'loss': 2.2719, 'learning_rate': 1.1689974046917128e-05, 'epoch': 1.25}\n",
      "{'loss': 2.2463, 'learning_rate': 1.1438002368533778e-05, 'epoch': 1.29}\n",
      "{'loss': 2.3335, 'learning_rate': 1.1186030690150429e-05, 'epoch': 1.32}\n",
      "{'loss': 2.2488, 'learning_rate': 1.0934059011767077e-05, 'epoch': 1.36}\n",
      "{'loss': 2.2094, 'learning_rate': 1.0682591276740494e-05, 'epoch': 1.4}\n",
      "{'loss': 2.2814, 'learning_rate': 1.0430619598357145e-05, 'epoch': 1.44}\n",
      "{'loss': 2.2328, 'learning_rate': 1.0178647919973797e-05, 'epoch': 1.47}\n",
      "{'loss': 2.2405, 'learning_rate': 9.926676241590446e-06, 'epoch': 1.51}\n",
      "{'loss': 2.22, 'learning_rate': 9.674704563207097e-06, 'epoch': 1.55}\n",
      "{'loss': 2.2608, 'learning_rate': 9.422732884823747e-06, 'epoch': 1.59}\n",
      "{'loss': 2.2549, 'learning_rate': 9.170761206440397e-06, 'epoch': 1.63}\n",
      "{'loss': 2.164, 'learning_rate': 8.918789528057046e-06, 'epoch': 1.66}\n",
      "{'loss': 2.226, 'learning_rate': 8.667321793030465e-06, 'epoch': 1.7}\n",
      "{'loss': 2.1747, 'learning_rate': 8.41585405800388e-06, 'epoch': 1.74}\n",
      "{'loss': 2.1386, 'learning_rate': 8.163882379620532e-06, 'epoch': 1.78}\n",
      "{'loss': 2.1582, 'learning_rate': 7.911910701237181e-06, 'epoch': 1.81}\n",
      "{'loss': 2.1632, 'learning_rate': 7.659939022853833e-06, 'epoch': 1.85}\n",
      "{'loss': 2.1332, 'learning_rate': 7.407967344470482e-06, 'epoch': 1.89}\n",
      "{'loss': 2.1951, 'learning_rate': 7.1559956660871325e-06, 'epoch': 1.93}\n",
      "{'loss': 2.2009, 'learning_rate': 6.904023987703783e-06, 'epoch': 1.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576496491cc444f5b77adc24793c0f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.022162914276123, 'eval_runtime': 19.8886, 'eval_samples_per_second': 591.294, 'eval_steps_per_second': 73.912, 'epoch': 2.0}\n",
      "{'loss': 2.1199, 'learning_rate': 6.652556252677199e-06, 'epoch': 2.0}\n",
      "{'loss': 2.14, 'learning_rate': 6.40058457429385e-06, 'epoch': 2.04}\n",
      "{'loss': 2.1327, 'learning_rate': 6.148612895910501e-06, 'epoch': 2.08}\n",
      "{'loss': 2.0482, 'learning_rate': 5.8966412175271504e-06, 'epoch': 2.12}\n",
      "{'loss': 2.0838, 'learning_rate': 5.644669539143801e-06, 'epoch': 2.15}\n",
      "{'loss': 2.1741, 'learning_rate': 5.393201804117217e-06, 'epoch': 2.19}\n",
      "{'loss': 2.0584, 'learning_rate': 5.141230125733868e-06, 'epoch': 2.23}\n",
      "{'loss': 2.0864, 'learning_rate': 4.889258447350518e-06, 'epoch': 2.27}\n",
      "{'loss': 2.1298, 'learning_rate': 4.637286768967168e-06, 'epoch': 2.31}\n",
      "{'loss': 2.0758, 'learning_rate': 4.385315090583819e-06, 'epoch': 2.34}\n",
      "{'loss': 2.1086, 'learning_rate': 4.133343412200469e-06, 'epoch': 2.38}\n",
      "{'loss': 2.044, 'learning_rate': 3.881371733817119e-06, 'epoch': 2.42}\n",
      "{'loss': 2.0795, 'learning_rate': 3.630407942147303e-06, 'epoch': 2.46}\n",
      "{'loss': 2.0992, 'learning_rate': 3.3784362637639535e-06, 'epoch': 2.49}\n",
      "{'loss': 2.0937, 'learning_rate': 3.1264645853806035e-06, 'epoch': 2.53}\n",
      "{'loss': 2.0911, 'learning_rate': 2.874492906997254e-06, 'epoch': 2.57}\n",
      "{'loss': 2.0696, 'learning_rate': 2.622521228613904e-06, 'epoch': 2.61}\n",
      "{'loss': 2.1098, 'learning_rate': 2.3705495502305543e-06, 'epoch': 2.65}\n",
      "{'loss': 2.0675, 'learning_rate': 2.1185778718472043e-06, 'epoch': 2.68}\n",
      "{'loss': 2.0388, 'learning_rate': 1.866606193463855e-06, 'epoch': 2.72}\n",
      "{'loss': 2.1036, 'learning_rate': 1.614634515080505e-06, 'epoch': 2.76}\n",
      "{'loss': 2.0287, 'learning_rate': 1.3626628366971553e-06, 'epoch': 2.8}\n",
      "{'loss': 2.0847, 'learning_rate': 1.1111951016705722e-06, 'epoch': 2.83}\n",
      "{'loss': 2.0811, 'learning_rate': 8.592234232872226e-07, 'epoch': 2.87}\n",
      "{'loss': 2.0798, 'learning_rate': 6.072517449038728e-07, 'epoch': 2.91}\n",
      "{'loss': 2.0137, 'learning_rate': 3.552800665205231e-07, 'epoch': 2.95}\n",
      "{'loss': 2.0231, 'learning_rate': 1.0330838813717339e-07, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be5ff0555514856b0c2d1cf7ea8ecbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9867643117904663, 'eval_runtime': 19.498, 'eval_samples_per_second': 603.14, 'eval_steps_per_second': 75.393, 'epoch': 3.0}\n",
      "{'train_runtime': 2924.7538, 'train_samples_per_second': 108.555, 'train_steps_per_second': 13.569, 'train_loss': 2.2956298002265676, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=39687, training_loss=2.2956298002265676, metrics={'train_runtime': 2924.7538, 'train_samples_per_second': 108.555, 'train_steps_per_second': 13.569, 'train_loss': 2.2956298002265676, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_masked\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=1000,\n",
    "    optim=\"adafactor\",\n",
    "    fp16=True,\n",
    "    # load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# NOTE: There's a HuggingFace bug on this; will fix later \n",
    "# (validate that eval_loss doesn't worsen by manual inspection for now)\n",
    "# early_stopping = EarlyStoppingCallback(\n",
    "#     early_stopping_patience=3, early_stopping_threshold=0.03\n",
    "# )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokens[\"train\"],\n",
    "    eval_dataset=tokens[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    # callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
