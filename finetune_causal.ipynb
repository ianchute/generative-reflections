{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import partial\n",
    "\n",
    "REGEX_MULTI_SPACE = re.compile(\"\\s+\")\n",
    "\n",
    "\n",
    "def preprocess_text(_re, _regex, s):\n",
    "    return {\n",
    "        \"text\": _re.sub(_regex, \" \", s[\"title\"])\n",
    "        # + \"\\n\\n\"\n",
    "        # + _re.sub(_regex, \" \", s[\"abstract\"])\n",
    "    }\n",
    "    \n",
    "partial_preprocess_text = partial(preprocess_text, re, REGEX_MULTI_SPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'abstract', 'text'],\n",
       "        num_rows: 105832\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'abstract', 'text'],\n",
       "        num_rows: 11760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"aalksii/ml-arxiv-papers\")\n",
    "dataset = dataset.map(\n",
    "    partial_preprocess_text,\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "# def add_tokens(tokenizer, new_tokens):\n",
    "    # new_tokens = set(new_tokens) - set(tokenizer.vocab.keys())\n",
    "    # tokenizer.add_tokens(list(new_tokens))\n",
    "    # return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(tokenizer, examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "\n",
    "partial_tokenize_function = partial(tokenize_function, tokenizer)\n",
    "\n",
    "tokens = dataset.map(\n",
    "    partial_tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edc4c02ef4d4123a9dd150216b9b140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9543, 'learning_rate': 1.9749540151686952e-05, 'epoch': 0.04}\n",
      "{'loss': 4.5818, 'learning_rate': 1.949807241666037e-05, 'epoch': 0.08}\n",
      "{'loss': 4.4567, 'learning_rate': 1.924610073827702e-05, 'epoch': 0.11}\n",
      "{'loss': 4.3533, 'learning_rate': 1.899412905989367e-05, 'epoch': 0.15}\n",
      "{'loss': 4.3255, 'learning_rate': 1.8742157381510318e-05, 'epoch': 0.19}\n",
      "{'loss': 4.2333, 'learning_rate': 1.849018570312697e-05, 'epoch': 0.23}\n",
      "{'loss': 4.2168, 'learning_rate': 1.823821402474362e-05, 'epoch': 0.26}\n",
      "{'loss': 4.2227, 'learning_rate': 1.798624234636027e-05, 'epoch': 0.3}\n",
      "{'loss': 4.192, 'learning_rate': 1.773427066797692e-05, 'epoch': 0.34}\n",
      "{'loss': 4.1175, 'learning_rate': 1.748229898959357e-05, 'epoch': 0.38}\n",
      "{'loss': 4.0573, 'learning_rate': 1.7230327311210222e-05, 'epoch': 0.42}\n",
      "{'loss': 4.0865, 'learning_rate': 1.697835563282687e-05, 'epoch': 0.45}\n",
      "{'loss': 4.039, 'learning_rate': 1.672638395444352e-05, 'epoch': 0.49}\n",
      "{'loss': 4.028, 'learning_rate': 1.6474412276060173e-05, 'epoch': 0.53}\n",
      "{'loss': 4.0168, 'learning_rate': 1.6222440597676824e-05, 'epoch': 0.57}\n",
      "{'loss': 4.0165, 'learning_rate': 1.5970468919293475e-05, 'epoch': 0.6}\n",
      "{'loss': 3.9779, 'learning_rate': 1.5718497240910123e-05, 'epoch': 0.64}\n",
      "{'loss': 3.9657, 'learning_rate': 1.546702950588354e-05, 'epoch': 0.68}\n",
      "{'loss': 3.9524, 'learning_rate': 1.521505782750019e-05, 'epoch': 0.72}\n",
      "{'loss': 3.9414, 'learning_rate': 1.4963086149116841e-05, 'epoch': 0.76}\n",
      "{'loss': 3.9446, 'learning_rate': 1.4711114470733492e-05, 'epoch': 0.79}\n",
      "{'loss': 3.9399, 'learning_rate': 1.4459646735706908e-05, 'epoch': 0.83}\n",
      "{'loss': 3.9129, 'learning_rate': 1.4207675057323557e-05, 'epoch': 0.87}\n",
      "{'loss': 3.9011, 'learning_rate': 1.3955703378940209e-05, 'epoch': 0.91}\n",
      "{'loss': 3.9053, 'learning_rate': 1.370373170055686e-05, 'epoch': 0.94}\n",
      "{'loss': 3.8545, 'learning_rate': 1.3452263965530275e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aebcb094e6948108cf747775b934b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.735496759414673, 'eval_runtime': 13.2368, 'eval_samples_per_second': 888.436, 'eval_steps_per_second': 111.054, 'epoch': 1.0}\n",
      "{'loss': 3.8386, 'learning_rate': 1.3200292287146925e-05, 'epoch': 1.02}\n",
      "{'loss': 3.777, 'learning_rate': 1.2948320608763576e-05, 'epoch': 1.06}\n",
      "{'loss': 3.79, 'learning_rate': 1.2696348930380227e-05, 'epoch': 1.1}\n",
      "{'loss': 3.8055, 'learning_rate': 1.2444881195353644e-05, 'epoch': 1.13}\n",
      "{'loss': 3.7811, 'learning_rate': 1.2192909516970292e-05, 'epoch': 1.17}\n",
      "{'loss': 3.7469, 'learning_rate': 1.1940937838586944e-05, 'epoch': 1.21}\n",
      "{'loss': 3.7534, 'learning_rate': 1.1688966160203595e-05, 'epoch': 1.25}\n",
      "{'loss': 3.7403, 'learning_rate': 1.1437498425177012e-05, 'epoch': 1.29}\n",
      "{'loss': 3.7467, 'learning_rate': 1.1185526746793662e-05, 'epoch': 1.32}\n",
      "{'loss': 3.732, 'learning_rate': 1.0934059011767077e-05, 'epoch': 1.36}\n",
      "{'loss': 3.7481, 'learning_rate': 1.0682087333383728e-05, 'epoch': 1.4}\n",
      "{'loss': 3.7348, 'learning_rate': 1.043011565500038e-05, 'epoch': 1.44}\n",
      "{'loss': 3.7655, 'learning_rate': 1.0178143976617029e-05, 'epoch': 1.47}\n",
      "{'loss': 3.7549, 'learning_rate': 9.926172298233679e-06, 'epoch': 1.51}\n",
      "{'loss': 3.7004, 'learning_rate': 9.67420061985033e-06, 'epoch': 1.55}\n",
      "{'loss': 3.7165, 'learning_rate': 9.42222894146698e-06, 'epoch': 1.59}\n",
      "{'loss': 3.734, 'learning_rate': 9.17025726308363e-06, 'epoch': 1.63}\n",
      "{'loss': 3.7141, 'learning_rate': 8.918789528057046e-06, 'epoch': 1.66}\n",
      "{'loss': 3.7253, 'learning_rate': 8.666817849673697e-06, 'epoch': 1.7}\n",
      "{'loss': 3.7077, 'learning_rate': 8.414846171290347e-06, 'epoch': 1.74}\n",
      "{'loss': 3.7068, 'learning_rate': 8.162874492906998e-06, 'epoch': 1.78}\n",
      "{'loss': 3.7247, 'learning_rate': 7.911406757880414e-06, 'epoch': 1.81}\n",
      "{'loss': 3.6806, 'learning_rate': 7.659939022853833e-06, 'epoch': 1.85}\n",
      "{'loss': 3.6965, 'learning_rate': 7.407967344470482e-06, 'epoch': 1.89}\n",
      "{'loss': 3.6975, 'learning_rate': 7.1559956660871325e-06, 'epoch': 1.93}\n",
      "{'loss': 3.6801, 'learning_rate': 6.904023987703783e-06, 'epoch': 1.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae5d44bb778453ab6fd3189a9d35f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.626753807067871, 'eval_runtime': 13.4091, 'eval_samples_per_second': 877.019, 'eval_steps_per_second': 109.627, 'epoch': 2.0}\n",
      "{'loss': 3.6955, 'learning_rate': 6.6520523093204325e-06, 'epoch': 2.0}\n",
      "{'loss': 3.6218, 'learning_rate': 6.400080630937083e-06, 'epoch': 2.04}\n",
      "{'loss': 3.6337, 'learning_rate': 6.148108952553733e-06, 'epoch': 2.08}\n",
      "{'loss': 3.6108, 'learning_rate': 5.896137274170384e-06, 'epoch': 2.12}\n",
      "{'loss': 3.6299, 'learning_rate': 5.644669539143801e-06, 'epoch': 2.15}\n",
      "{'loss': 3.6417, 'learning_rate': 5.3926978607604504e-06, 'epoch': 2.19}\n",
      "{'loss': 3.6116, 'learning_rate': 5.140726182377102e-06, 'epoch': 2.23}\n",
      "{'loss': 3.6321, 'learning_rate': 4.888754503993752e-06, 'epoch': 2.27}\n",
      "{'loss': 3.6034, 'learning_rate': 4.637286768967168e-06, 'epoch': 2.31}\n",
      "{'loss': 3.6104, 'learning_rate': 4.3858190339405855e-06, 'epoch': 2.34}\n",
      "{'loss': 3.6213, 'learning_rate': 4.133847355557236e-06, 'epoch': 2.38}\n",
      "{'loss': 3.6167, 'learning_rate': 3.8818756771738855e-06, 'epoch': 2.42}\n",
      "{'loss': 3.6264, 'learning_rate': 3.629903998790536e-06, 'epoch': 2.46}\n",
      "{'loss': 3.6271, 'learning_rate': 3.3784362637639535e-06, 'epoch': 2.49}\n",
      "{'loss': 3.6398, 'learning_rate': 3.1264645853806035e-06, 'epoch': 2.53}\n",
      "{'loss': 3.6243, 'learning_rate': 2.874492906997254e-06, 'epoch': 2.57}\n",
      "{'loss': 3.5911, 'learning_rate': 2.622521228613904e-06, 'epoch': 2.61}\n",
      "{'loss': 3.6211, 'learning_rate': 2.3705495502305543e-06, 'epoch': 2.65}\n",
      "{'loss': 3.6283, 'learning_rate': 2.1185778718472043e-06, 'epoch': 2.68}\n",
      "{'loss': 3.583, 'learning_rate': 1.866606193463855e-06, 'epoch': 2.72}\n",
      "{'loss': 3.6399, 'learning_rate': 1.614634515080505e-06, 'epoch': 2.76}\n",
      "{'loss': 3.6223, 'learning_rate': 1.363166780053922e-06, 'epoch': 2.8}\n",
      "{'loss': 3.6269, 'learning_rate': 1.111699045027339e-06, 'epoch': 2.83}\n",
      "{'loss': 3.5808, 'learning_rate': 8.597273666439893e-07, 'epoch': 2.87}\n",
      "{'loss': 3.6284, 'learning_rate': 6.077556882606396e-07, 'epoch': 2.91}\n",
      "{'loss': 3.6126, 'learning_rate': 3.557840098772898e-07, 'epoch': 2.95}\n",
      "{'loss': 3.6169, 'learning_rate': 1.0381233149394009e-07, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83d74fc2b7441369f45eb868efa8055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.5998127460479736, 'eval_runtime': 13.135, 'eval_samples_per_second': 895.318, 'eval_steps_per_second': 111.915, 'epoch': 3.0}\n",
      "{'train_runtime': 2525.5688, 'train_samples_per_second': 125.713, 'train_steps_per_second': 15.714, 'train_loss': 3.8243711187380116, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=39687, training_loss=3.8243711187380116, metrics={'train_runtime': 2525.5688, 'train_samples_per_second': 125.713, 'train_steps_per_second': 15.714, 'train_loss': 3.8243711187380116, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_causal\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=1000,\n",
    "    optim=\"adafactor\",\n",
    "    fp16=True,\n",
    "    # load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# NOTE: There's a HuggingFace bug on this; will fix later \n",
    "# (validate that eval_loss doesn't worsen by manual inspection for now)\n",
    "# early_stopping = EarlyStoppingCallback(\n",
    "#     early_stopping_patience=3, early_stopping_threshold=0.03\n",
    "# )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokens[\"train\"],\n",
    "    eval_dataset=tokens[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    # callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
